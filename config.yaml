# RAG Pipeline Configuration (Simplified)

# LLM Settings
llm:
  provider: "openai"
  model: "gpt-4-turbo-preview"
  temperature: 0.7
  max_tokens: 2000

# Embeddings Settings
embeddings:
  provider: "openai"
  model: "text-embedding-3-small"
  dimension: 1536
  batch_size: 100

# Vector Store Settings
vector_store:
  type: "chroma"
  collection_name: "rag_documents"
  persist_directory: "./data/chroma_db"

# Document Processing Settings
document_processing:
  chunk_size: 1000
  chunk_overlap: 200
  separators: ["\n\n", "\n", " ", ""]

# Retrieval Settings
retrieval:
  search_type: "similarity"
  k: 4
  score_threshold: 0.7

# Hybrid Search Settings
hybrid_search:
  enabled: true
  min_vector_results: 2

# Conversation Settings
conversation:
  enabled: true
  persist_directory: "./data/conversations"
  max_history: 10

# Data Paths
paths:
  documents: "./data/documents"
  processed: "./data/processed"
  logs: "./logs"

# API Settings
api:
  host: "0.0.0.0"
  port: 8000

# Logging
logging:
  level: "INFO"
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
  rotation: "500 MB"
  retention: "10 days"
